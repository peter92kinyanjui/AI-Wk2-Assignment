{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODwEIVoYjvXT",
        "outputId": "e45a7f3e-04f7-4825-c598-ccaf92442ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species  \n",
            "0        0  \n",
            "1        0  \n",
            "2        0  \n",
            "3        0  \n",
            "4        0  \n",
            "\n",
            "Missing values in the dataset:\n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "species              0\n",
            "dtype: int64\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Classical ML with Scikit-learn\n",
        "# Dataset: Iris Species Dataset\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Iris dataset\n",
        "# The dataset can be loaded from sklearn or directly from a CSV file\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels (species)\n",
        "\n",
        "# Convert to DataFrame for easier manipulation\n",
        "iris_df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
        "iris_df['species'] = y\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(iris_df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in the dataset:\")\n",
        "print(iris_df.isnull().sum())\n",
        "\n",
        "# Since the Iris dataset does not have missing values, we can proceed to encode the labels\n",
        "# Encoding the target labels (species)\n",
        "label_encoder = LabelEncoder()\n",
        "iris_df['species'] = label_encoder.fit_transform(iris_df['species'])\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "X = iris_df.drop('species', axis=1)  # Features\n",
        "y = iris_df['species']  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "# Evaluate the model using accuracy, precision, and recall\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Optional: Display the feature importance\n",
        "feature_importance = decision_tree.feature_importances_\n",
        "for feature, importance in zip(iris.feature_names, feature_importance):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ]
    }
  ]
}